---
title: "ST-540  Assignment-5"
author: "Tilekbek Zhoroev"
date: "3/4/2022"
output: pdf_document
---

```{r, echo=FALSE,include=FALSE}
library(tibble)
library(ggplot2)
library(tidyr)
library(dplyr)
library(invgamma)
library(ggforce)
library(rjags)
library(BEST)
library(broom)
```


**Problem 1**

In Section 2.4 we compared Reggie Jackson's home run rate in the regular season and World Series. He hit 563 home runs in 2820 regular-season games and 10 home runs in 27 World Series games (a player can hit 0, 1, 2, ... home runs in a game). Assuming Uniform(0,10) priors for both home run rates, use JAGS to summarize the posterior distribution of (i) his home run rate in the regular season, (ii) his home run rate in the World Series, and (iii) the ratio
of these rates. Provide trace plots for all three parameters and  discuss convergence of the MCMC sampler including appropriate convergence diagnostics.

*Solution*
Here we have given the Poisson likelihood and uniform prior.

```{r}
# Given parameters
N1 = 2820; Y1 = 563; N2 = 27; Y2 = 10
# define string model
model_string <- textConnection("model{
    # Likelihood
    Y1 ~ dpois(N1*lambda1)
    Y2 ~ dpois(N2*lambda2)
    # Priors
    lambda1 ~  dunif(0, 10)
    lambda2 ~  dunif(0, 10)
    r <- lambda2/lambda1
 }")
# initizalize the parameters
inits <- list(lambda1= Y1/N1,lambda2 = Y2/N2)
# Load the data and compile the MCMC code
data <- list(N1 = N1,Y1 = Y1,N2 = N2,Y2 = Y2)
model <- jags.model(model_string,data = data, inits=inits, n.chains=2)
#Burn-in for 10000 samples
update(model, 15000, progress.bar="none")


 params  <- c("lambda1","lambda2","r")
 samples <- coda.samples(model, 
            variable.names=params, 
            n.iter=30000, progress.bar="none")
```
```{r fig.width=6, fig.height=8}
plot(samples)
```
```{r}
summary(samples)

effectiveSize(samples)



gelman.diag(samples)
  
```
The trace plots look great, the effective sample sizes are all large (over 32000), and the Gelman-Rubin statistics are 1.0. Therefore, the chains have clearly converged.


**Problem2**


A clinical trial gave six subjects a placebo and six subjects a new
weight loss medication. The response variable is the change in
weight (pounds) from baseline (so -2.0 means the subject lost 2
pounds). The data for the 12 subjects are:

|Placebo| Treatment|
|:----------------------|:-----------------------|
| 2.0 | -3.5|
|-3.1 | -1.6|
|-1.0 | -4.6|
| 0.2 | -0.9|
| 0.3 | -5.1|
| 0.4 |  0.1|


Conduct a Bayesian analysis to compare the means of these two
groups. Would you say the treatment is effective? Is your conclusion
sensitive to the prior?



*Solution*

Let us assume two different cases, (i) two groups have same variance and different variances. In first case, let the placebo group is $Y_i\sim^{iid} \mathcal{N}(\mu,\sigma^2)$ for $i = 1,2,...,n_1$ and  treatment group is $Y_i\sim^{iid} \mathcal{N}(\mu+\delta,\sigma^2)$ for $i = n_1+1,n_1+2,...,n_1+n_2=n.$ Here we would like to analyze whether $\delta=0$ or not. Since, the true variance of the groups are unknown we would like to  use Jeffrey's prior $\pi(\mu, \delta, \sigma^2)$ the  the marginal posterior distribution of $\delta$ integrating over both $\mu$ and $\sigma^2$ is $$ \delta|rest \sim t_{n}\Bigg[ \bar Y_2- \bar Y_1,\hat\sigma^2\bigg( \frac{1}{n_1}+\frac{1}{n_2}\bigg)\Bigg].$$ where $\hat Y_1$ and $\hat Y_2$ are the mean of Placebo and Treatment group, respectively.

In second case we assume $Y_i\sim^{iid} \mathcal{N}(\mu,\sigma_1^2)$ for $i = 1,2,...,n_1$ and $Y_i\sim^{iid} \mathcal{N}(\mu+\delta,\sigma_2^2)$ for $i = n_1+1,n_1+2,...,n_1+n_2=n.$ Then the posterior can be approximated by MCMC.


```{r}
Y1 = c(2.0, -3.1, -1.0,0.2,0.3,0.4)
Y2 = c(-3.5, -1.6, -4.6,-0.9,-5.1,0.1)

Ybar1 <- mean(Y1)
s21 <- mean((Y1-Ybar1)^2)
n1 <- length(Y1)

 # Statistics from group 2
Ybar2 <- mean(Y2)
s22 <- mean((Y2-Ybar2)^2)
n2 <- length(Y2)

# Posterior of the difference assuming equal variance
delta_hat <- Ybar2-Ybar1
s2 <- (n1*s21 + n2*s22)/(n1+n2)
scale <- sqrt(s2)*sqrt(1/n1+1/n2)
df <- n1+n2
cred_int <- delta_hat + scale*qt(c(0.025,0.975),df=df)
delta_hat
cred_int

 # Posterior of delta assuming unequal variance using MC sampling
mu1 <- Ybar1 + sqrt(s21/n1)*rt(1000000,df=n1)
mu2 <- Ybar2 + sqrt(s22/n2)*rt(1000000,df=n2)
delta <- mu2-mu1

hist(delta,main="Posterior distribution of the difference in means",xlim = c(-9,4), breaks = 100)
quantile(delta,c(0.025,0.975)) # 95% credible set

#other way of representation
Bay_model= BESTmcmc(Y2, Y1)
plot(Bay_model)

```

From here we observe that if we take same variance that 0 is not included in credible interval. We can say that the treatment is effective, but we would like to check sensitivity of these results. The next case show us that the credible interval is includes the 0. Hence, it's sensitive to the choice of priors.



**Problem3**

The response variable is `medv`, the median value of owner-occupied
homes (in $1,000s), and the other 13 variables are covariates that
describe the neighborhood.

(a) Fit a Bayesian linear regression model with uninformative
Gaussian priors for the regression coefficients. Verify the
MCMC sampler has converged, and summarize the posterior
distribution of all regression coefficients.

(b) Perform a classic least squares analysis (e.g., using the lm function
in R). Compare the results numerically and conceptually
with the Bayesian results.

 (c) Refit the Bayesian model with double exponential priors for the
regression coefficients, and discuss how the results differ from
the analysis with uninformative priors.

(d) Fit a Bayesian linear regression model in (a) using only the first
500 observations and compute the posterior predictive distribution
for the final 6 observations. Plot the posterior predictive
distribution versus the actual value for these 6 observations and
comment on whether the predictions are reasonable.

*Solution*

(a) Before we start let us explore the given data is there any missing terms?
```{r, warning=FALSE}
library(MASS)
data(Boston)
summary(Boston)
```

We observe that all entries are filled. Next, we would like to construct Bayesian model with uninformative Gaussian prior.

```{r}
Y = Boston%>%
  dplyr::select(medv)
Y = as.matrix(Y)
X = Boston%>%
  dplyr::select(-medv)

X <- scale(X) # standardize covariates
X <- cbind(1,X) # add intercept
colnames(X)[1] = "Intercept" 
names = colnames(X)

#load given data
data <- list(n=length(Y),p=ncol(X),Y=Y,X=X)

# define model string
model_string <- textConnection("model{
# Likelihood
for(i in 1:n){
Y[i,] ~ dnorm(inprod(X[i,],beta[]),tau)
}
# Priors
for(j in 1:p){beta[j] ~ dnorm(0, 0.0001)}
tau ~ dgamma(0.01,0.01)
}")

model <- jags.model(model_string, data = data, n.chains=2,quiet=TRUE)
update(model, 10000, progress.bar="none")
params <- c("beta")
samples <- coda.samples(model, variable.names=params, n.iter=10000,progress.bar="none")
```

```{r}
effectiveSize(samples)
gelman.diag(samples)
sum                      <- summary(samples)
rownames(sum$statistics) <- names
rownames(sum$quantiles)  <- names
sum$statistics           <- round(sum$statistics,4)
sum$quantiles            <- round(sum$quantiles,4)
sum
```

Since the effective size is more than 1400 and and the Gelman-Rubin statistics are 1.0. Therefore, the chains have clearly converged.

(b)

```{r}
ols_data = cbind(Y,X[,2:14])
ols_data = data.frame(ols_data)
ols_model = lm(medv~.-medv, data = ols_data)
#ols_model$coefficients
tidy(ols_model)
```

The are numerically almost equivalent. However, in Bayesian approach this is parameter rather than fixed number. Hence, all coefficients have distributions. Even though, their representation are same, their interpratations are completely different.


(c)

```{r}
 model_string <- textConnection("model{
   # Likelihood
    for(i in 1:n){
      Y[i,] ~ dnorm(alpha+inprod(X[i,],beta[]),taue)
    }
   # Priors
    for(j in 1:p){
      beta[j] ~ ddexp(0,taue*taub)
    }
    alpha ~ dnorm(0,0.001)
    taue  ~ dgamma(0.1, 0.1)
    taub  ~ dgamma(0.1, 0.1)
 }")

 model <- jags.model(model_string,data = data, n.chains = 2,quiet=TRUE)
update(model, 10000, progress.bar="none")
 samples2 <- coda.samples(model, variable.names=params, n.iter=10000,progress.bar="none")
```


```{r}
effectiveSize(samples2)
gelman.diag(samples2)
sum                      <- summary(samples2)
rownames(sum$statistics) <- names
rownames(sum$quantiles)  <- names
sum$statistics           <- round(sum$statistics,4)
sum$quantiles            <- round(sum$quantiles,4)
sum
```


```{r figures-side, fig.show="hold", out.width="33%"}
for(j in 2:14){

 # Collect the MCMC iteration from both chains for the three priors

 s1 <- c(samples[[1]][,j],samples[[2]][,j])
 s2 <- c(samples2[[1]][,j],samples2[[2]][,j])

 # Get smooth density estimate for each prior

 d1 <- density(s1)
 d2 <- density(s2)


 # Plot the density estimates

 mx <- max(c(d1$y,d2$y))

 plot(d1$x,d1$y,type="l",ylim=c(0,mx),xlab=expression(beta),ylab="Posterior density",main=names[j])
 lines(d2$x,d2$y,lty=2)
 abline(v=0)
 legend(1, 95, legend=c("Uninformative Gaussian", "Bayesian LASSO"),
       col=c("red", "blue"), lty=1:2, cex=0.8)
}
```

Since we have enough data points the choice of prior have only minor affect. It also shown in figures.

(d)

```{r}
Y_train = Y[1:500,]
Y_test = Y[501:506,]
X_train = X[1:500,]
X_test = X[501:506,]
n_train    <- length(Y_train)
n_test    <- length(Y_test)
p     <- ncol(X_train)

model_string <- textConnection("model{

  # Likelihood
  for(i in 1:no){
    Yo[i]   ~ dnorm(muo[i],inv.var)
    muo[i] <- alpha + inprod(Xo[i,],beta[])
  }

  # Prediction
  for(i in 1:np){
    Y_test[i]  ~ dnorm(mup[i],inv.var)
    mup[i] <- alpha + inprod(Xp[i,],beta[])
  }

  # Priors
  for(j in 1:p){
    beta[j] ~ dnorm(0,0.0001)
  }
  alpha     ~ dnorm(0, 0.01)
  inv.var   ~ dgamma(0.01, 0.01)
  sigma     <- 1/sqrt(inv.var)
}")

data = list(Yo=Y_train,no=n_train,np=n_test,p=p,Xo=X_train,Xp=X_test)

model <- jags.model(model_string, data = data)

```
```{r}
update(model, 10000, progress.bar="none")

samp <- coda.samples(model, 
        variable.names=c("beta","sigma","Y_test","alpha"), 
        n.iter=20000, progress.bar="none")

summary(samp[,-c(1:n_test)])
```
```{r}
samps       <- samp[[1]]
 Y_test.samps    <- samps[,1:n_test] 
 alpha.samps <- samps[,n_test+1]
 beta.samps  <- samps[,n_test+1+1:p]
 sigma.samps <- samps[,ncol(samps)]

# Compute the posterior mean for the plug-in predictions  

 beta.mn  <- colMeans(beta.samps)
 sigma.mn <- mean(sigma.samps)
 alpha.mn <- mean(alpha.samps) 


# Plot the PPD and plug-in

 for(j in 1:6){

    # Plug-in
    mu <- alpha.mn+sum(X_test[j,]*beta.mn)
    y  <- rnorm(20000,mu,sigma.mn)
    plot(density(y),col=2,xlab="Y",main="PPD")

    # PPD
    lines(density(Y_test.samps[,j]))

    # Truth
    abline(v=Y_test[j],col=3,lwd=2)

    legend("topright",c("PPD","Plug-in","Truth"),col=1:3,lty=1,inset=0.05)
 }
```


From plots we observe that both plug-in prediction and PPD give reasonable predictions.





